{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNz2nD5f1k/jReyddkFhe0X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jfodera/proj-ai-ml/blob/main/homeworks/hw2/hw2_Background.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0munLI9HToBW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Background Learned/Reviewed from Homework2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-l6ZX1HouPiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Things learned/reviewed.\n",
        "- In this class if 'should I write some comments' is a common question, air on the side of doing one making some.\n",
        "- Parameters change with models\n",
        "- Decision Tree Classifier (CART) has the followinn in Scikit:\n",
        "1. **max_depth:** The max depth of the tree where we will stop splitting the nodes. Lower will make your model faster but not as accurate; higher can give you accuracy but risks overfitting and may be slow.\n",
        "\n",
        "2. **min_samples_split:** The minimum number of samples required to split a node. There exists a trade-off between smaller minimum count and a larger one. Try finding out how this helps combat overfitting.\n",
        "\n",
        "3. **max_features:** The number of features to consider when looking for the best split. Higher means potentially better results with the tradeoff of training taking longer.\n",
        "\n",
        "4. **min_impurity_split:** Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold. This can be used to tradeoff combating overfitting (high value, small tree) vs high accuracy (low value, big tree).\n",
        "- scikit-learn and sklearn refer to the exact same thing\n",
        "- One of the main points of the pandas library is to view tabular data`\n",
        "- IPython, Jupyter, (and therefore Co-lab) only display the expression if it is the final line (like `df.head`)\n",
        "- When working with a Decision Tree Classifier, cross validation is more common to utilize\n",
        "  - it is also not really neccessary and bad in some cases to run VIF with Dec Tree Classifiers\n",
        "    - but it is good practice for logistic regression and linear models"
      ],
      "metadata": {
        "id": "77bYmtdgT3fT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python/Sklearn notes\n",
        "- `shotData = shotData.drop('LOC_X', axis=1)`\n",
        "  - axis specifies if you want to drop row or column, first argument is label of said row or column\n",
        "    - 0-row\n",
        "    - 1-column\n",
        "- DecisionTreeClassifier will not work with anything that is not fully numeric.\n",
        "- `\n",
        "cat_cols = shotData_x.select_dtypes(include=['object','category']).colums.tolist()`\n",
        "  - object - simplu strings, mixed types, or python objects\n",
        "  - categoryies - cols that have been explicitly converted to pandas categorical dtype (like the position the player plays)\n",
        "- `ColumnTransformer`\n",
        "  - applies different transformations to different groups of columns\n",
        "  - `transformers` - What transformation to do to what columns\n",
        "    - each transformation is a tuple with 3 parts\n",
        "      - `name` - simply a name for the transformer\n",
        "      - `transformer object` - more below\n",
        "      - list of column names to apply the transformation to\n",
        "\n",
        "  - `remainder` - what to do with columns not listed in transformers\n",
        "    - set to `drop` - all unmentioned columns are removed from output\n",
        "    - set to `passthrough` - all unmentioned columns are kept unchanged\n",
        "- Transformation Objects:\n",
        "  - `ordinal`\n",
        "    - better for trees\n",
        "    - best for things with some sort of natural ranking or order\n",
        "    - `handle_unknown='use_encoded_value'` simply tells us that instead of erroring, assign the fixed value defined in `unkown_value`\n",
        "      - you could run into unkowns when the information is already split into test and train, and when your testing\n",
        "    ```\n",
        "    red → 0\n",
        "    blue → 1\n",
        "    green → 2 (arbitrary or ordered)\n",
        "    ```\n",
        "  - `oneHot`\n",
        "    - Better for linear models\n",
        "    - better for things with no natural order\n",
        "    ```\n",
        "    red → [1, 0, 0]\n",
        "    blue → [0, 1, 0]\n",
        "    green → [0, 0, 1]\n",
        "    ```\n",
        "- **Dataframes** - pandas object that is easily represented as rows and columns\n",
        "  - can use .head() for it\n",
        "- Booleans work fine with decsision tree classifier\n",
        "\n",
        "- Callingh a DecisionTreeClassifier() with no arguments creats a permissive decision tree that grows as large as possible until unable to split, and is unpruned\n",
        "- min_impurity_decrease = min_impurity_split\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xRGCstxSTyp9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Terminology Helper\n",
        "- **Gini Index** - is an attribute selection method that helps assess how well a particular split classifies.\n",
        "- **ASM** - Broader term that stands for attribute selection method. Helps to pick what attribute should use to split\n",
        "  - Gini Index is an ASM\n",
        "- **[Kaggle](https://www.kaggle.com/)** - Very useful dataset site to utilize for machine learning projects.\n",
        "- **Dropping Features** - it is not 'bad practice' to drop features and sometimes neccessary\n",
        "- **CART** - The algorithim for decision Tree Classifiers\n",
        "- **IPython** is interactive interface on top of Python\n",
        "- **Tree Inductons** - the process of actually building or learning the decsision tree model from the data\n",
        "- **Cross Validation** - data set is split up into k-folds (equal parts)\n",
        "  - there are usually 5 or 10 folds\n",
        "  - for each fold, you train on k-1 folds, and validate on the remaining fold)\n",
        "  - you then average the k scores and that is your cross validation estimate\n",
        "- **Imputation** - replacing missing values in a dataset with estimated or substituted values\n",
        "- Feature perturbation usually means temporarily modifying or removing features on already-trained models to see how much the model's output changes.\n",
        "\n"
      ],
      "metadata": {
        "id": "TGwNhbjCTz8j"
      }
    }
  ]
}